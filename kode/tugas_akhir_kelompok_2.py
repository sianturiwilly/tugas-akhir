# -*- coding: utf-8 -*-
"""tugas-akhir-kelompok-2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gBIRwMvP16AI1KiHa7jD75A6CrxqyRHh

# 1. Reza
"""

!pip install scikit-learn --upgrade

!pip install mlxtend --upgrade

!pip install gradio

import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt 
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from mlxtend.evaluate import bias_variance_decomp
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn import datasets
from sklearn import svm
from sklearn import metrics 
from sklearn.cluster import KMeans
from sklearn.preprocessing import MinMaxScaler

df = pd.read_csv("sample_data/supermarket_sales.csv")
df.head()

df['Date']=pd.to_datetime(df['Date'])
df['Year']=pd.to_datetime(df["Date"]).dt.year
df['Month']=pd.to_datetime(df["Date"]).dt.month
df['Weekday Name']=df["Date"].dt.day_name()
df.head()

df.info()

df.isnull().sum()

sns.barplot(x="Product line",y="Quantity", data=df)
plt.xticks(rotation=80)
plt.yticks(rotation=45)
plt.grid(ls=':', color='grey')
plt.show()

sns.barplot(x="Product line",y="Rating", data=df)
plt.xticks(rotation=80)
plt.yticks(rotation=45)
plt.grid(ls=':', color='grey')
plt.show()

sns.barplot(x="Product line", y="Quantity", hue="Gender", data=df)
plt.xticks(rotation=90)
plt.yticks(rotation=45)
plt.grid(ls=':', color='grey')
plt.show()

sns.barplot(x="Product line", y="Quantity", hue="Payment", data=df)
plt.xticks(rotation=90)
plt.yticks(rotation=45)
plt.grid(ls=':', color='grey')
plt.show()

sns.barplot(x="Product line",y="Quantity", hue="Customer type",data=df)
plt.xticks(rotation=80)
plt.yticks(rotation=30)
plt.grid(ls=':', color='grey')
plt.show()

"""# 2. Perwira"""

sns.barplot(x="City",y="Quantity", data=df)
plt.xticks(rotation=30)
plt.yticks(rotation=45)
plt.grid(ls=':', color='grey')
plt.show()

sns.barplot(x="City",y="gross income", data=df)
plt.xticks(rotation=30)
plt.yticks(rotation=45)
plt.grid(ls=':', color='grey')
plt.show()

std_value=df[["Quantity"]].groupby(df["Date"]).mean()
std_value.plot(linewidth=1.2);
plt.grid(ls=':', color='grey')

std_value2=df[["Quantity", "gross income"]].groupby(df["Date"]).mean()
std_value2.plot(linewidth=1.2);
plt.grid(ls=':', color='grey')

std_value3=df[["Quantity", "Rating"]].groupby(df["Date"]).mean()
std_value3.plot(linewidth=1.2);
plt.grid(ls=':', color='grey')

# Plotting heatmap 
sns.heatmap(df.corr(), square=True, annot=True)

df.corr() # Terdapat korelasi quantity dan unit price sebesar 0,01 sehingga berbanding terbalik.

sns.lmplot(x = 'cogs', y = 'Total', data=df)

X = df[['Unit price', 'cogs', 'Total', 'gross income']].to_numpy()
y = df['Quantity'].to_numpy()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)

"""X adalah variabel independen dan y adalah variabel target atau output.

test_size adalah proporsi data yang akan kita gunakan untuk testing. 0.3 artinya, kita menggunakan 30% data kita untuk testing (70% nya digunakan untuk training).

random_size digunakan untuk me-random data sebanyak yang kita tentukan.

# 3. Willi

## Trade-off
"""

model1 = svm.SVC()
model2 = LinearRegression()
model3 = KNeighborsClassifier()
model4 = GaussianNB()

from sklearn.metrics import mean_squared_error

mse1, bias1, var1 = bias_variance_decomp(model1, X_train, y_train, X_test, y_test, loss="mse", random_seed=100)
mse2, bias2, var2 = bias_variance_decomp(model2, X_train, y_train, X_test, y_test, loss="mse", random_seed=100)
mse3, bias3, var3 = bias_variance_decomp(model3, X_train, y_train, X_test, y_test, loss="mse", random_seed=100)
mse4, bias4, var4 = bias_variance_decomp(model4, X_train, y_train, X_test, y_test, loss="mse", random_seed=100)

print("=SVM=")

print("MSE: %.3f" % mse1)
print("Bias: %.3f" % bias1)
print("Variance: %.3f" % var1)

print("=LINEAR=")

print("MSE: %.3f" % mse2)
print("Bias: %.3f" % bias2)
print("Variance: %.3f" % var2)

print("=KNN=")

print("MSE: %.3f" % mse3)
print("Bias: %.3f" % bias3)
print("Variance: %.3f" % var3)

print("=NB=")

print("MSE: %.3f" % mse4)
print("Bias: %.3f" % bias4)
print("Variance: %.3f" % var4)

X = df[['Unit price', 'cogs', 'Total', 'gross income']].to_numpy()
y = df['Quantity'].to_numpy()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)

model1 = svm.SVC()
dataset = {
    "random_state": [], 
    "mse": [],
    "bias": [],
    "variance": []
}
for i in range(1, 11):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i)
    mse, bias, var = bias_variance_decomp(model1, X_train, y_train, X_test, y_test, loss="mse", random_seed=100)
    dataset['random_state'].append(i)
    dataset['mse'].append(mse)
    dataset['bias'].append(bias) 
    dataset['variance'].append(var)
    
df = pd.DataFrame(dataset)
df

# Create lmplot
sns.lmplot(x='variance', y='bias', data=df)

# Show figure
plt.show()

"""# 4. Serly

## Cross-validation
"""

from sklearn.model_selection import cross_val_score

score_cv = cross_val_score(svm.SVC(kernel="linear"), X, y, cv=5)
print(score_cv)
print("Rata: ", score_cv.mean() * 100, "%")

score_cv = cross_val_score(LinearRegression(), X, y, cv=5)
print(score_cv)
print("Rata: ", score_cv.mean() * 100, "%")

score_cv = cross_val_score(KNeighborsClassifier(n_neighbors=6), X, y, cv=5)
print(score_cv)
print("Rata: ", score_cv.mean() * 100, "%")

score_cv = cross_val_score(GaussianNB(), X, y, cv=5)
print(score_cv)
print("Rata: ", score_cv.mean() * 100, "%")

"""## Training Data"""

regressor = svm.SVC(kernel="linear")

regressor.fit(X_train, y_train)

y_predict = regressor.predict(X_test)

"""# Evaluasi Model

Buat memastikan model yang kita buat cukup akurat atau belum dalam memprediksi.
"""

metrics.accuracy_score(y_test, y_predict) * 100

"""Score ada di rentangan (0%-100%). Semakin mendekati 100, semakin akurat model yang kita bangun.

Score yang kita peroleh memiliki akurasi sebesar 100% dan cukup akurat.

Jika kita menggunakan lebih dari satu variabel independen, akurasinya bisa lebih baik.

# Gradio
"""

regressor.coef_, regressor.intercept_

import gradio as gr

def predict(Unit_price, cogs, Total, gross_income):
  return regressor.predict([[Unit_price, cogs, Total, gross_income]])[0]

demo = gr.Interface(predict, 
                    [gr.Number(label="Unit price"), gr.Number(label="cogs"), gr.Number(label="Total"), gr.Number(label="gross income"),], 
                    gr.Number())

demo.launch()